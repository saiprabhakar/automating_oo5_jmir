{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import openai\n",
    "from vertexai.language_models import TextGenerationModel\n",
    "\n",
    "import constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cred.json', 'r') as f:\n",
    "    cred_json = json.load(f)\n",
    "\n",
    "openai.api_key = cred_json['api_key']\n",
    "openai.organization_id = cred_json['organization_id']\n",
    "# list_models = openai.Model.list()\n",
    "# [x.id for x in list_models['data'] if 'gpt' in x.id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Good morning, Ms. Smith!',\n",
       "  'How are you feeling today?',\n",
       "  'Morning, Doctor.'],\n",
       " [0, 1, 2],\n",
       " [12, 13, 14, 17, 18, 30])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract conversations and gt\n",
    "example_sentences, example_sentences_idx, gt_idx = [], [], []\n",
    "with open('example_conv_sents.txt', 'r') as f:\n",
    "    file_lines = f.read().splitlines()\n",
    "    for x in file_lines:\n",
    "        x = x.strip()\n",
    "\n",
    "        if not x:\n",
    "            continue\n",
    "        if x.startswith(\"gt\"):\n",
    "            idx = int(x[3:].split(\":\")[0])\n",
    "            sent = \":\".join(x[3:].strip().split(\":\")[1:]).strip()\n",
    "            gt_idx.append(idx)\n",
    "        else:\n",
    "            idx = int(x.split(\":\")[0])\n",
    "            sent = \":\".join(x.split(\":\")[1:]).strip()\n",
    "\n",
    "        example_sentences.append(sent)\n",
    "        example_sentences_idx.append(idx)\n",
    "\n",
    "example_sentences[:3], example_sentences_idx[:3], gt_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_numbers(numbers, threshold):\n",
    "    \"\"\"\n",
    "    Clusters numbers that are within `threshold` of each other\n",
    "    \"\"\"\n",
    "    clusters = []\n",
    "    current_cluster = []\n",
    "    # Sort the numbers in ascending order\n",
    "    numbers.sort()\n",
    "    # cluster number within threshold\n",
    "    for i in range(len(numbers)):\n",
    "        if not current_cluster:\n",
    "            current_cluster.append(numbers[i])\n",
    "        else:\n",
    "            if numbers[i] - current_cluster[-1] <= threshold:\n",
    "                current_cluster.append(numbers[i])\n",
    "            else:\n",
    "                clusters.append(current_cluster.copy())\n",
    "                current_cluster = [numbers[i]]\n",
    "    # consider the last cluster that was not appended\n",
    "    if current_cluster:\n",
    "        clusters.append(current_cluster)\n",
    "    return clusters\n",
    "\n",
    "def isoverlap(range1, range2):\n",
    "    if range1[0] <= range2[1] and range1[1] >= range2[0]:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def calculate_precision_recall(gt_ranges_expanded, pred_ranges):\n",
    "    true_positives, false_positives, false_negatives = 0, 0, 0\n",
    "    tp_clusters_in_gt_expanded, tp_clusters_in_pred = [], []\n",
    "    fn_clusters_in_gt_expanded, fn_clusters_in_pred = [], []\n",
    "    # compare gt and pred clusters to find true positives and false negatives\n",
    "    for gt_range in gt_ranges_expanded:\n",
    "        overlap_found = False\n",
    "        for pred_range in pred_ranges:\n",
    "            if isoverlap(pred_range, gt_range):\n",
    "                overlap_found = True\n",
    "                break\n",
    "        if overlap_found:\n",
    "            true_positives += 1\n",
    "            tp_clusters_in_gt_expanded.append(gt_range)\n",
    "            tp_clusters_in_pred.append(pred_range)\n",
    "        else:\n",
    "            false_negatives += 1\n",
    "            fn_clusters_in_gt_expanded.append(gt_range)\n",
    "            fn_clusters_in_pred.append(pred_range)\n",
    "\n",
    "    # compare gt and pred clusters to find false positives\n",
    "    fp_clusters_in_pred = []    \n",
    "    for pred_range in pred_ranges:\n",
    "        overlap_found = False\n",
    "        for gt_range in gt_ranges_expanded:\n",
    "            if isoverlap(pred_range, gt_range):\n",
    "                overlap_found = True\n",
    "                break\n",
    "        if not overlap_found:\n",
    "            false_positives += 1\n",
    "            fp_clusters_in_pred.append(pred_range)\n",
    "    \n",
    "    # calculate precision and recall\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "    \n",
    "    cluster_types = {\n",
    "        'tp_clusters_in_gt_expanded': tp_clusters_in_gt_expanded,\n",
    "        'tp_clusters_in_pred': tp_clusters_in_pred,\n",
    "        'fn_clusters_in_pred': fn_clusters_in_pred,\n",
    "        'fn_clusters_in_gt_expanded': fn_clusters_in_gt_expanded,\n",
    "        'fp_clusters_in_pred': fp_clusters_in_pred}\n",
    "    agg_info = {\n",
    "        'precision': precision, 'recall': recall,\n",
    "        'true_positives': true_positives,\n",
    "        'false_positives': false_positives,\n",
    "        'false_negatives': false_negatives,\n",
    "    }\n",
    "    return agg_info, cluster_types\n",
    "\n",
    "def get_metrics(y_idx, pred_idx):\n",
    "    # cluster the indices\n",
    "    y_clusters = cluster_numbers(y_idx, constants.PROIMITY_THRESHOLD)\n",
    "    pred_clusters = cluster_numbers(pred_idx, constants.PROIMITY_THRESHOLD)\n",
    "    # expand the gt by offset\n",
    "    y_idx_expanded = sorted(set([\n",
    "        x \n",
    "        for y_idx in y_clusters\n",
    "        for y in y_idx\n",
    "        for x in range(y-constants.OFFSET, y+constants.OFFSET+1)\n",
    "    ]))\n",
    "    y_clusters_expanded = cluster_numbers(y_idx_expanded, 1)\n",
    "\n",
    "    # convert the clusters to ranges\n",
    "    y_range_expanded = [[x[0], x[-1]] for x in y_clusters_expanded]\n",
    "    pred_ranges = [[x[0], x[-1]] for x in pred_clusters]\n",
    "    \n",
    "    # find precision and recall by finding overlapping ranges\n",
    "    metrics, clusters = calculate_precision_recall(y_range_expanded, pred_ranges)\n",
    "    return metrics, clusters\n",
    "\n",
    "def parse_and_get_utt_ids_v3(input_string):\n",
    "    input_string = input_string.lower()\n",
    "    matches = re.findall(r'<(.*?)>', input_string)\n",
    "    matches = [\n",
    "        x.replace('sentence ids', '').replace('sentence id', '').replace('sentence', '')\n",
    "        for x in matches]\n",
    "    matches = [\n",
    "        \" \".join(x.replace(',', ' ').replace(':', ' ').replace('-', ' ').replace('/', ' ').strip().split())\n",
    "        for x in matches]\n",
    "\n",
    "    # print(matches)\n",
    "    sentence_ids = []\n",
    "\n",
    "    for match in matches:\n",
    "        assert bool(re.search(r'[^0-9. ]', match)) == False, f\"Invalid output format {match}\"\n",
    "\n",
    "        ranges = re.findall(r'\\d+\\.\\d+|\\d+', match)\n",
    "        if not ranges: # this can happen if the sentence ids are empty\n",
    "            continue\n",
    "        \n",
    "        # Check if it's a range or a single ID\n",
    "        if len(ranges) == 2:\n",
    "            start, end = int(float(ranges[0])), int(float(ranges[1]))\n",
    "            for i in range(start, end + 1):\n",
    "                sentence_ids.append(i)\n",
    "        else:\n",
    "            sentence_ids.append(int(float(ranges[0])))\n",
    "    return sentence_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_google_prompt(messages):\n",
    "    prompt = []\n",
    "    for m in messages:\n",
    "        if m['role'] == 'system':\n",
    "            content = [m['content'], '']\n",
    "        elif m['role'] == 'user':\n",
    "            content = ['Input:', m['content']]\n",
    "        else:\n",
    "            content = ['Output:', m['content'], '']\n",
    "        prompt.extend(content)\n",
    "        \n",
    "    prompt = \"\\n\".join(prompt)\n",
    "    return prompt\n",
    "\n",
    "def format_conv(utterances, utterances_ids):\n",
    "    formatted_conv = []\n",
    "    for utterance, utterance_id in zip(utterances, utterances_ids):\n",
    "        formatted_conv.append(f'{utterance_id} - {utterance}')\n",
    "    return \"\\n\".join(formatted_conv)\n",
    "\n",
    "def get_messages(utterances, utterances_ids, use_few_shot=False,\n",
    "                 example_inputs=None, example_outputs=None,\n",
    "                 use_explanation=True):\n",
    "    formatted_conv = format_conv(utterances, utterances_ids)\n",
    "    messages = [{\"role\": \"system\", \"content\": constants.system_prompt}]\n",
    "\n",
    "    if use_explanation:\n",
    "        option_prompt = constants.option_prompt_original\n",
    "    else:\n",
    "        option_prompt = constants.option_prompt_no_explanation\n",
    "        \n",
    "    if use_few_shot:\n",
    "        for _, (example_input, example_output)  in enumerate(zip(example_inputs, example_outputs)):\n",
    "            messages.append(\n",
    "                {\"role\": \"user\", \"content\": f'Conversation:\\n{example_input}\\nInstruction:{option_prompt}'},\n",
    "            )\n",
    "            messages.append(\n",
    "                {\"role\": \"assistant\", \"content\": example_output}\n",
    "            )\n",
    "    messages.append(\n",
    "        {\"role\": \"user\", \"content\": f'Conversation:\\n{formatted_conv}\\nInstruction:{option_prompt}'}\n",
    "    )\n",
    "    return messages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate and save outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running gpt-3.5-turbo-0301\n",
      "running gpt-3.5-turbo-0301\n",
      "running gpt-3.5-turbo-0301\n",
      "running gpt-3.5-turbo-0301\n"
     ]
    }
   ],
   "source": [
    "fileid = \"example\"\n",
    "response_all = defaultdict(list)\n",
    "eval_options = [\n",
    "    ('gpt-3.5-turbo-0301', True, True),\n",
    "    ('gpt-3.5-turbo-0301', False, True),\n",
    "    ('gpt-3.5-turbo-0301', False, False),\n",
    "    ('gpt-3.5-turbo-0301', True, False),\n",
    "    # ('text-bison@001', True, True),\n",
    " ]\n",
    "tag = f'_1'\n",
    "\n",
    "for model, use_few_shot, use_explanation in eval_options:\n",
    "    print('running', model)\n",
    "\n",
    "    idx = list(range(0, len(example_sentences), constants.BATCH_SIZE))\n",
    "    example_sentences_idx = list(range(len(example_sentences)))\n",
    "\n",
    "    for batchid, (st, end) in enumerate(zip(idx[:], idx[1:] + [len(example_sentences)])):\n",
    "        utterances = example_sentences[st:end]\n",
    "        utterances_ids = example_sentences_idx[st:end]\n",
    "        \n",
    "        # Create a list of message objects\n",
    "        start_offset = list(utterances_ids)[0] if constants.USE_ZERO_ALL_BATCHES else 0\n",
    "        messages = get_messages(utterances, [x-start_offset for x in utterances_ids],\n",
    "                                use_few_shot=use_few_shot,\n",
    "                                example_inputs=constants.example_inputs,\n",
    "                                example_outputs=constants.example_outputs, use_explanation=use_explanation)\n",
    "        \n",
    "        if 'bison' in model:\n",
    "            google_prompt = get_google_prompt(messages)\n",
    "            parameters = {\n",
    "                \"max_output_tokens\": 256,\n",
    "                \"temperature\": 0.0,\n",
    "                \"top_p\": 1,\n",
    "                \"top_k\": 40\n",
    "            }\n",
    "            google_model = TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
    "            response = google_model.predict(\n",
    "                google_prompt,\n",
    "                **parameters\n",
    "            )\n",
    "\n",
    "            response_all[f\"{fileid}_{tag}_{model}_fewshot_{use_few_shot}_useexp_{use_explanation}\"].append({\n",
    "                'vendor': 'google', 'utterances_ids': utterances_ids, 'response': response,\n",
    "                \"messages\": messages, \"google_prompt\": google_prompt, \"model\": model, 'start_idx': start_offset})\n",
    "        else:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "                temperature=0.0,\n",
    "                top_p=1,\n",
    "            )\n",
    "        response_all[f\"{fileid}_{tag}_{model}_fewshot_{use_few_shot}_useexp_{use_explanation}\"].append({\n",
    "            'utterances_ids': utterances_ids, 'response': response, \"messages\": messages, 'start_offset': start_offset})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-3.5-turbo-0301 True True\n",
      "pred_sentence_ids_list_all [10, 11, 12, 14, 16, 17, 18, 21, 22, 24, 25, 26] gt_idx [12, 13, 14, 17, 18, 30]\n",
      "clusters {'tp_clusters_in_gt_expanded': [[11, 19]], 'tp_clusters_in_pred': [[10, 18]], 'fn_clusters_in_pred': [[21, 26]], 'fn_clusters_in_gt_expanded': [[29, 31]], 'fp_clusters_in_pred': [[21, 26]]}\n",
      "metrics {'precision': 0.5, 'recall': 0.5, 'true_positives': 1, 'false_positives': 1, 'false_negatives': 1}\n",
      "\n",
      "gpt-3.5-turbo-0301 False True\n",
      "pred_sentence_ids_list_all [10, 14, 15, 17, 18, 21, 22, 24, 25, 26] gt_idx [12, 13, 14, 17, 18, 30]\n",
      "clusters {'tp_clusters_in_gt_expanded': [[11, 19]], 'tp_clusters_in_pred': [[14, 18]], 'fn_clusters_in_pred': [[21, 26]], 'fn_clusters_in_gt_expanded': [[29, 31]], 'fp_clusters_in_pred': [[10, 10], [21, 26]]}\n",
      "metrics {'precision': 0.3333333333333333, 'recall': 0.5, 'true_positives': 1, 'false_positives': 2, 'false_negatives': 1}\n",
      "\n",
      "gpt-3.5-turbo-0301 False False\n",
      "pred_sentence_ids_list_all [10, 14, 15, 17, 18, 21, 22, 24, 25, 26] gt_idx [12, 13, 14, 17, 18, 30]\n",
      "clusters {'tp_clusters_in_gt_expanded': [[11, 19]], 'tp_clusters_in_pred': [[14, 18]], 'fn_clusters_in_pred': [[21, 26]], 'fn_clusters_in_gt_expanded': [[29, 31]], 'fp_clusters_in_pred': [[10, 10], [21, 26]]}\n",
      "metrics {'precision': 0.3333333333333333, 'recall': 0.5, 'true_positives': 1, 'false_positives': 2, 'false_negatives': 1}\n",
      "\n",
      "gpt-3.5-turbo-0301 True False\n",
      "pred_sentence_ids_list_all [10, 11, 12, 14, 16, 17, 18, 21, 22, 24, 25, 26] gt_idx [12, 13, 14, 17, 18, 30]\n",
      "clusters {'tp_clusters_in_gt_expanded': [[11, 19]], 'tp_clusters_in_pred': [[10, 18]], 'fn_clusters_in_pred': [[21, 26]], 'fn_clusters_in_gt_expanded': [[29, 31]], 'fp_clusters_in_pred': [[21, 26]]}\n",
      "metrics {'precision': 0.5, 'recall': 0.5, 'true_positives': 1, 'false_positives': 1, 'false_negatives': 1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display_metric = []\n",
    "for model, use_few_shot, use_explanation in eval_options:\n",
    "    print(model, use_few_shot, use_explanation)\n",
    "    metrics_all = defaultdict(list)\n",
    "\n",
    "    llm_out = response_all[f\"{fileid}_{tag}_{model}_fewshot_{use_few_shot}_useexp_{use_explanation}\"]\n",
    "    \n",
    "    pred_sentence_ids_list_all = []\n",
    "    for llm_response in llm_out:\n",
    "        if 'bison' in model:\n",
    "            out = llm_response['response'].text.strip()\n",
    "        else:\n",
    "            out = llm_response['response'].choices[0].message[\"content\"].strip()\n",
    "\n",
    "        pred_sentence_ids_list = parse_and_get_utt_ids_v3(out)\n",
    "        start_offset = llm_response.get('start_offset', 0)\n",
    "\n",
    "        pred_sentence_ids_list = [int(start_offset + x) for x in pred_sentence_ids_list]\n",
    "        \n",
    "        input_utterances_ids = [int(x) for x in set(llm_response['utterances_ids'])]\n",
    "        not_found = []\n",
    "        for sentence_id in pred_sentence_ids_list:\n",
    "            if sentence_id not in input_utterances_ids:\n",
    "                print(\"Sentence ID {} not found in utterances\".format(sentence_id))\n",
    "                not_found.append(sentence_id)\n",
    "        for id in not_found:\n",
    "            pred_sentence_ids_list.remove(id)\n",
    "        pred_sentence_ids_list_all.extend(pred_sentence_ids_list)\n",
    "\n",
    "    pred_array = [1 if x in pred_sentence_ids_list_all else 0 for x in example_sentences_idx]\n",
    "    pred_sentence_ids_list_all = list(set(pred_sentence_ids_list_all))\n",
    "    metrics, clusters = get_metrics(gt_idx, pred_sentence_ids_list_all)\n",
    "    print('pred_sentence_ids_list_all', pred_sentence_ids_list_all, 'gt_idx', gt_idx)\n",
    "    print('clusters', clusters)\n",
    "    print('metrics', metrics)\n",
    "    print()\n",
    "    \n",
    "    for k, v in metrics.items():\n",
    "        metrics_all[k].append(v)\n",
    "\n",
    "    precisiondenominator = max(1, sum(metrics_all['true_positives']) + sum(metrics_all['false_positives']))\n",
    "    recalldenominator = max(1, sum(metrics_all['true_positives']) + sum(metrics_all['false_negatives']))\n",
    "    precision = sum(metrics_all['true_positives'])/precisiondenominator\n",
    "    recall = sum(metrics_all['true_positives'])/recalldenominator\n",
    "    f1 = 2*precision*recall/max(precision+recall, 1)\n",
    "\n",
    "    display_metric.append({\n",
    "        'tag': tag,\n",
    "        'model':model, 'use_few_shot': use_few_shot,\n",
    "        'precision': precision, 'recall': recall, 'f1': f1,\n",
    "        'num_file': 1, 'use_explanation': use_explanation\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>model</th>\n",
       "      <th>use_few_shot</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>num_file</th>\n",
       "      <th>use_explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_1</td>\n",
       "      <td>gpt-3.5-turbo-0301</td>\n",
       "      <td>True</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_1</td>\n",
       "      <td>gpt-3.5-turbo-0301</td>\n",
       "      <td>False</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>_1</td>\n",
       "      <td>gpt-3.5-turbo-0301</td>\n",
       "      <td>False</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_1</td>\n",
       "      <td>gpt-3.5-turbo-0301</td>\n",
       "      <td>True</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tag               model  use_few_shot  precision  recall        f1  \\\n",
       "0  _1  gpt-3.5-turbo-0301          True   0.500000     0.5  0.500000   \n",
       "1  _1  gpt-3.5-turbo-0301         False   0.333333     0.5  0.333333   \n",
       "2  _1  gpt-3.5-turbo-0301         False   0.333333     0.5  0.333333   \n",
       "3  _1  gpt-3.5-turbo-0301          True   0.500000     0.5  0.500000   \n",
       "\n",
       "   num_file  use_explanation  \n",
       "0         1             True  \n",
       "1         1             True  \n",
       "2         1            False  \n",
       "3         1            False  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df = pd.DataFrame(display_metric)\n",
    "metrics_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optalk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
